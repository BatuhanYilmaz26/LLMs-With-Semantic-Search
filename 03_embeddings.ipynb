{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Embeddings\n",
    "- Embeddings are numerical representations of text that computers can more easily process. \n",
    "- This makes them one of the most important components of large language models. \n",
    "\n",
    "| Embeddings          | Word Embeddings        |\n",
    "| ---------------------------------- | -------------------------------- |\n",
    "| ![](images/embeddings.png)  | ![](images/word_embeddings.png) |\n",
    "\n",
    "- As you can see in this embedding, similar words are grouped together. \n",
    "- So in the top left you have sports, in the bottom left you have houses and buildings and castles, in the bottom right you have vehicles like bikes and cars, and in the top right you have fruits. \n",
    "- So the apple would go among the fruits. \n",
    "- Then the coordinates for Apple here are 5'5 because we are associating each word in the table in the right to two numbers, the horizontal and the vertical coordinate. \n",
    "- This is an embedding. \n",
    "- Now this embedding sends each word to two numbers like this. \n",
    "- In general, embeddings would send words to a lot more numbers and we would have all the possible words. \n",
    "- Embeddings that we use in practice could send a word to hundreds of different numbers or even thousands. \n",
    "\n",
    "### Setup\n",
    "Load needed API keys and relevant Python libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cohere umap-learn altair datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client(os.environ['COHERE_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "\n",
    "Consider a very small dataset of three words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_words = pd.DataFrame({'text':\n",
    "  [\n",
    "      'joy',\n",
    "      'happiness',\n",
    "      'potato'\n",
    "  ]})\n",
    "\n",
    "three_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the embeddings for the three words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_words_emb = co.embed(texts=list(three_words['text']),\n",
    "                           model='embed-english-v2.0').embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_1 = three_words_emb[0]\n",
    "word_2 = three_words_emb[1]\n",
    "word_3 = three_words_emb[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Embeddings\n",
    "\n",
    "![](images/text_embeddings.png)\n",
    "\n",
    "In this example here, we have embeddings for sentences. \n",
    "- Now the sentences get sent to a vector or a list of numbers. \n",
    "- And notice that that the first sentence is, hello, how are you? The last one is, hi, how's it going? And they don't have the same words, but they are very similar. \n",
    "- And because they're very similar, the embedding sends them to numbers that are really close to each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to take a look at a small data set of sentences. \\\n",
    "This one has eight sentences, as you can see. They are in pairs. Each one is the answer to the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.DataFrame({'text':\n",
    "  [\n",
    "   'Where is the world cup?',\n",
    "   'The world cup is in Qatar',\n",
    "   'What color is the sky?',\n",
    "   'The sky is blue',\n",
    "   'Where does the bear live?',\n",
    "   'The bear lives in the the woods',\n",
    "   'What is an apple?',\n",
    "   'An apple is a fruit',\n",
    "  ]})\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the embeddings for the three sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = co.embed(texts=list(sentences['text']),\n",
    "               model='embed-english-v2.0').embeddings\n",
    "\n",
    "# Explore the 10 first entries of the embeddings of the 3 sentences:\n",
    "for e in emb:\n",
    "    print(e[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how many numbers are associated to each one of the sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(emb[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular case it's 4096, but different embeddings have different lengths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import umap\n",
    "#import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import umap_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = umap_plot(sentences, emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart.interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wiki_articles = pd.read_pickle('wikipedia.pkl')\n",
    "wiki_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import umap_plot_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = wiki_articles[['title', 'text']]\n",
    "embeds = np.array([d for d in wiki_articles['emb']])\n",
    "\n",
    "chart = umap_plot_big(articles, embeds)\n",
    "chart.interactive()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
