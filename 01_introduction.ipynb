{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This course consists of the following topics. \\\n",
    "- First, it shows you how to use basic **keyword search**, which is also called **lexical search**, which powered a lot of search systems before large language models. \n",
    "  - It consists of finding the documents that has the highest amount of matching words with the query. \n",
    "- Then you learn how to enhance this type of keyword search with a method called **re-rank**. \n",
    "  - As the name suggests, this then ranks the responses by relevance with the query. \n",
    "\n",
    "|              |                          |\n",
    "| ---------------------------------- | -------------------------------- |\n",
    "| ![](images/keyword.png)  | ![](images/rerank.png) |\n",
    "\n",
    "- After this, you learn a more advanced method of search, which has vastly improved the results of keyword search, as it tries to use the actual meaning or the actual semantic meaning of the text with which to carry out the search. \n",
    "- This method is called **dense retrieval**. \n",
    "  - This uses a very powerful tool in natural language processing called **embeddings**, which is a way to associate a vector of numbers with every piece of text. \n",
    "  - **Semantic search** consists of finding the closest documents to the query in the space of embeddings. \n",
    "- Similar to other models, search algorithms need to be properly evaluated. \n",
    "  - You also learn effective ways to do this. \n",
    "\n",
    "|              |                          |\n",
    "| ---------------------------------- | -------------------------------- |\n",
    "| ![](images/dense_retrieval.png)  | ![](images/evaluation.png) |\n",
    "\n",
    "- Finally, since LLMs can be used to generate answers, you also learn how to plug in the search results into an LLM and have it generate an answer based on them. \n",
    "- **Dense retrieval with embeddings** vastly improves the question answering capabilities of an LLM as it  first searches for and retrieves the relevant documents and it creates an answer from this retrieved information.\n",
    "\n",
    "![](images/search_powered.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
